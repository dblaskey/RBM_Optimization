{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57967a8-2c0b-4c20-8c22-fd34c764f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimization of RBM ###\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/glade/work/dblaskey/RBM_opt_code/src')\n",
    "import MOASMO\n",
    "import Gen_Val_Inputs\n",
    "import convert_rbm_to_nc\n",
    "from convert_rbm_to_nc import read_config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "import _pickle as cPickle\n",
    "import pandas as pd\n",
    "import sampling\n",
    "import xarray as xr\n",
    "import seaborn as sn\n",
    "import GLP\n",
    "import gp\n",
    "import NSGA2\n",
    "import pickle\n",
    "import smt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import cmocean\n",
    "import hydroeval as he\n",
    "import glob\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import math\n",
    "import warnings\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d124ed1d-b8a0-4946-a16a-414e21d68a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate air temperature\n",
    "def mosheni(air_temp, alpha, beta, mu, gamma):\n",
    "    return mu + (alpha - mu)/(1 + math.exp(gamma*(beta-air_temp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb915e9-bb1b-491b-946f-89fe284c0f96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b3e82f-a4ee-49f4-8831-162882504c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Begin Code #####\n",
    "df_sites = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/Opt_Basins.csv', index_col=0)\n",
    "df_sites = df_sites[df_sites['type']==\"Opt\"]\n",
    "outlets = np.unique(df_sites.outlet_comid.values)\n",
    "\n",
    "# Read in Observed Data\n",
    "temp_data = pd.read_csv('/glade/scratch/dblaskey/RBM/temperature_gages.csv', index_col=0)\n",
    "df = pd.merge(temp_data, df_sites, on=\"site_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4478af77-22e2-4a2e-a340-aa218a91ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "psets_df = pd.read_csv('/glade/u/home/dblaskey/RBM/Optimization/Opt_runs_0.csv')\n",
    "psets_df.rename(columns={ psets_df.columns[0]: \"Name\" }, inplace = True)\n",
    "\n",
    "years = range(2013,2018)\n",
    "start_date = '2013-01-01'\n",
    "end_date = '2017-12-31'\n",
    "time_series = pd.date_range(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf136326-1ca3-479d-826e-a711992ea896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_regression(folder, outlet):\n",
    "    \n",
    "    # Calculate air temperature\n",
    "    def mosheni(air_temp):\n",
    "        return mu + (alpha - mu)/(1 + math.exp(gamma*(beta-air_temp)))\n",
    "\n",
    "    print(folder, outlet)\n",
    "    var_list = psets_df[psets_df['Name'] == folder]\n",
    "\n",
    "    alpha = var_list.alpha.values[0]\n",
    "    beta = var_list.beta.values[0]\n",
    "    mu = var_list.mu.values[0]\n",
    "    gamma = var_list.gamma.values[0]\n",
    "\n",
    "    Ordered_reaches_final = pd.read_csv(\"/glade/scratch/dblaskey/RBM/Input/%s_network.csv\"%outlet)\n",
    "     \n",
    "    for i, comid in enumerate(df_sites[df_sites['outlet_comid'] == outlet]['COMID'].values):\n",
    "        cell = Ordered_reaches_final[Ordered_reaches_final['hru'] == comid].node.values[0]\n",
    "        site_no = df_sites[df_sites['outlet_comid'] == outlet].index.values[i]\n",
    "\n",
    "        Water = []\n",
    "        for year in years:\n",
    "            test = pd.read_csv(\"/glade/scratch/dblaskey/RBM/RBM_Input/%s_energy_%s\"%(outlet,year), sep=\" \", header=None, names=[\"cell\", \"Tair\", \"vp\", \"SW\", \"LW\", \"Density\",\"P\",\"Wind\"])\n",
    "            test_id = test[test[\"cell\"] == cell]\n",
    "            test_id.drop(test_id.tail(1).index, inplace=True)\n",
    "            test_id['T_smooth'] = 0.1 * test_id['Tair'] + 0.9 * test_id['Tair'].shift()\n",
    "            test_id['T_smooth']=test_id['T_smooth'].fillna(test_id['Tair'])\n",
    "            Water.append(test_id.apply(lambda row : mosheni(row['T_smooth']), axis = 1))\n",
    "            \n",
    "        Water = np.concatenate(Water)                        \n",
    "        sim_df = pd.DataFrame(Water, index=time_series, columns=['sim'])\n",
    "        sim_df.index.name = 'Date'\n",
    "\n",
    "        # Filter to just one gage for observations\n",
    "        temp_df = df[df['site_no'] == site_no][['X_00010_00003', 'Date']]\n",
    "        temp_df = temp_df.rename(columns={\"X_00010_00003\": \"obs\"})\n",
    "        temp_df = temp_df.set_index('Date')\n",
    "        temp_df.index = pd.to_datetime(temp_df.index)\n",
    "\n",
    "        # Combine simulation and observation datasets\n",
    "        df_concat = pd.concat([sim_df, temp_df], axis=1)\n",
    "        df_concat = df_concat.dropna()\n",
    "        df_concat = df_concat.loc['2013-10-01':'2017-09-30']\n",
    "        df_concat = df_concat[df_concat.index.month.isin([5, 6, 7, 8, 9])]\n",
    "        df_concat = df_concat.reset_index()\n",
    "\n",
    "        df_concat.to_csv('/glade/scratch/dblaskey/RBM/Regression/Opt/%s/%s.csv' % (folder, comid))\n",
    "\n",
    "        return [he.evaluator(he.rmse, df_concat.sim.values, df_concat.obs.values)[0],\n",
    "                np.int(comid),\n",
    "                folder,\n",
    "                outlet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c089b-50ea-4e8d-a47c-6ef9760358c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe_basin_0_0000pe_basin_0_0000pe_basin_0_0001pe_basin_0_0001    81000433810000058100000581000433\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/dblaskey/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py:4164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "args_list = []\n",
    "for folder in np.unique(psets_df.Name.values)[:2]:\n",
    "    for outlet in outlets[:2]:\n",
    "        args_list.append((folder, outlet))\n",
    "\n",
    "#### Preprocess RBM #### \n",
    "# set up the multiprocessing pool\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "# run the function in parallel using the multiprocessing pool\n",
    "results = pool.starmap(cal_regression, args_list)\n",
    "\n",
    "# close the multiprocessing pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e7dd9-c545-40f9-b576-45b4a884ff14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6809500-0477-4b6b-81f9-9c0244015d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe_basin_0_0000\n",
      "pe_basin_0_0001\n",
      "pe_basin_0_0002\n",
      "pe_basin_0_0003\n",
      "pe_basin_0_0004\n",
      "pe_basin_0_0005\n",
      "pe_basin_0_0006\n",
      "pe_basin_0_0007\n",
      "pe_basin_0_0008\n",
      "pe_basin_0_0009\n",
      "pe_basin_0_0010\n",
      "pe_basin_0_0011\n",
      "pe_basin_0_0012\n",
      "pe_basin_0_0013\n",
      "pe_basin_0_0014\n",
      "pe_basin_0_0015\n",
      "pe_basin_0_0016\n",
      "pe_basin_0_0017\n",
      "pe_basin_0_0018\n",
      "pe_basin_0_0019\n",
      "pe_basin_0_0020\n",
      "pe_basin_0_0021\n",
      "pe_basin_0_0022\n",
      "pe_basin_0_0023\n",
      "pe_basin_0_0024\n",
      "pe_basin_0_0025\n",
      "pe_basin_0_0026\n",
      "pe_basin_0_0027\n",
      "pe_basin_0_0028\n",
      "pe_basin_0_0029\n",
      "pe_basin_0_0030\n",
      "pe_basin_0_0031\n",
      "pe_basin_0_0032\n",
      "pe_basin_0_0033\n",
      "pe_basin_0_0034\n",
      "pe_basin_0_0035\n",
      "pe_basin_0_0036\n",
      "pe_basin_0_0037\n",
      "pe_basin_0_0038\n",
      "pe_basin_0_0039\n",
      "pe_basin_0_0040\n",
      "pe_basin_0_0041\n",
      "pe_basin_0_0042\n",
      "pe_basin_0_0043\n",
      "pe_basin_0_0044\n",
      "pe_basin_0_0045\n",
      "pe_basin_0_0046\n",
      "pe_basin_0_0047\n",
      "pe_basin_0_0048\n",
      "pe_basin_0_0049\n",
      "pe_basin_0_0050\n",
      "pe_basin_0_0051\n",
      "pe_basin_0_0052\n",
      "pe_basin_0_0053\n",
      "pe_basin_0_0054\n",
      "pe_basin_0_0055\n",
      "pe_basin_0_0056\n",
      "pe_basin_0_0057\n",
      "pe_basin_0_0058\n",
      "pe_basin_0_0059\n",
      "pe_basin_0_0060\n",
      "pe_basin_0_0061\n",
      "pe_basin_0_0062\n",
      "pe_basin_0_0063\n",
      "pe_basin_0_0064\n",
      "pe_basin_0_0065\n",
      "pe_basin_0_0066\n",
      "pe_basin_0_0067\n",
      "pe_basin_0_0068\n",
      "pe_basin_0_0069\n",
      "pe_basin_0_0070\n",
      "pe_basin_0_0071\n",
      "pe_basin_0_0072\n",
      "pe_basin_0_0073\n",
      "pe_basin_0_0074\n",
      "pe_basin_0_0075\n",
      "pe_basin_0_0076\n",
      "pe_basin_0_0077\n",
      "pe_basin_0_0078\n",
      "pe_basin_0_0079\n",
      "pe_basin_0_0080\n",
      "pe_basin_0_0081\n",
      "pe_basin_0_0082\n",
      "pe_basin_0_0083\n"
     ]
    }
   ],
   "source": [
    "# Calculate air temperature\n",
    "def mosheni(air_temp):\n",
    "    return mu + (alpha - mu)/(1 + math.exp(gamma*(beta-air_temp)))\n",
    "\n",
    "RMSE =[]\n",
    "comid_list =[]\n",
    "name_list=[]\n",
    "outlet_list =[]\n",
    "with warnings.catch_warnings(record=True):\n",
    "    \n",
    "    for folder in np.unique(psets_df.Name.values):\n",
    "        print(folder)\n",
    "        var_list = psets_df[psets_df['Name'] == folder]\n",
    "\n",
    "        alpha = var_list.alpha.values[0]\n",
    "        beta = var_list.beta.values[0]\n",
    "        mu = var_list.mu.values[0]\n",
    "        gamma = var_list.gamma.values[0]\n",
    "\n",
    "        # Build Output Folders\n",
    "        path = '/glade/scratch/dblaskey/RBM/Regression/Opt/%s/'%folder\n",
    "        if os.path.exists(path) == False:           \n",
    "            print(\"Creating \", folder)\n",
    "            os.mkdir(path)\n",
    "\n",
    "        for outlet in outlets:\n",
    "            Ordered_reaches_final = pd.read_csv(\"/glade/scratch/dblaskey/RBM/Input/%s_network.csv\"%outlet)\n",
    "            \n",
    "            for i, comid in enumerate(df_sites[df_sites['outlet_comid'] == outlet]['COMID'].values):\n",
    "                cell = Ordered_reaches_final[Ordered_reaches_final['hru'] == comid].node.values[0]\n",
    "                site_no = df_sites[df_sites['outlet_comid'] == outlet].index.values[i]\n",
    "\n",
    "                Water = []\n",
    "                for year in years:\n",
    "                    test = pd.read_csv(\"/glade/scratch/dblaskey/RBM/RBM_Input/%s_energy_%s\"%(outlet,year), sep=\" \", header = None,\n",
    "                    names=[\"cell\", \"Tair\", \"vp\", \"SW\", \"LW\", \"Density\",\"P\",\"Wind\"])\n",
    "                    test_id = test[test[\"cell\"] == cell]\n",
    "                    test_id.drop(test_id.tail(1).index,inplace=True)\n",
    "                    test_id['T_smooth'] = 0.1 * test_id['Tair'] + 0.9 * test_id['Tair'].shift()\n",
    "                    test_id['T_smooth']=test_id['T_smooth'].fillna(test_id['Tair'])\n",
    "                    Water.append(test_id.apply(lambda row : mosheni(row['T_smooth']), axis = 1))\n",
    "\n",
    "                Water=np.concatenate(Water)                        \n",
    "                sim_df = pd.DataFrame(Water, index=time_series, columns=['sim'])\n",
    "                sim_df.index.name = 'Date'\n",
    "                sim_df.to_csv('/glade/scratch/dblaskey/RBM/Regression/Opt/%s/%s.csv'%(folder,comid))\n",
    "\n",
    "                # Filter to just one gage for observations\n",
    "                temp_df = df[df['site_no']==site_no][['X_00010_00003', 'Date']]\n",
    "                temp_df = temp_df.rename(columns={\"X_00010_00003\": \"obs\"})\n",
    "                temp_df = temp_df.set_index('Date')\n",
    "                temp_df.index = pd.to_datetime(temp_df.index)\n",
    "\n",
    "                # Combine simulation and observation datasets\n",
    "                df_concat = pd.concat([sim_df,temp_df],axis=1)\n",
    "                df_concat = df_concat.dropna()\n",
    "                df_concat = df_concat.loc['2013-10-01':'2017-09-30']\n",
    "                df_concat = df_concat[df_concat.index.month.isin([5,6,7,8,9])]\n",
    "                df_concat = df_concat.reset_index()\n",
    "\n",
    "                RMSE.append(he.evaluator(he.rmse, df_concat.sim.values, df_concat.obs.values)[0])\n",
    "                comid_list.append(np.int(comid))\n",
    "                name_list.append(folder)\n",
    "                outlet_list.append(outlet)\n",
    "warnings.warn(\"should not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24c431ce-23a8-431a-b60e-52cdc7af4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the results\n",
    "df_temp = pd.DataFrame({'temp_rmse': RMSE,  'COMID': comid_list, 'Name': name_list, 'Outlet': outlet_list})\n",
    "df2 = pd.merge(df_temp, df_sites, on=['COMID'])\n",
    "df2.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results.csv', index=False)\n",
    "\n",
    "df_LHS = df_temp.groupby('Name').mean(\"temp_rmse\").reset_index().drop(columns=['COMID', 'Outlet'])\n",
    "df_LHS = df_LHS.merge(psets_df)\n",
    "\n",
    "df_LHS = df_LHS.drop([\"min_velocity\", \"min_d\", \"min_w\"], axis = 1)\n",
    "\n",
    "df_LHS.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabef6a1-3fec-4288-9309-666f88053355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LHS = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full.csv')\n",
    "#d = preprocessing.normalize(df_LHS.drop([\"Name\", \"temp_rmse\"], axis = 1),axis=0,return_norm=True)\n",
    "#normalization_scalar = d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1c381b-3064-415f-8d81-1c4db2b89a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>mu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>a_d</th>\n",
       "      <th>b_d</th>\n",
       "      <th>a_w</th>\n",
       "      <th>b_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>pe_basin_0_0097</td>\n",
       "      <td>1.450777</td>\n",
       "      <td>12.557875</td>\n",
       "      <td>8.1875</td>\n",
       "      <td>2.841925</td>\n",
       "      <td>0.221925</td>\n",
       "      <td>2.164687</td>\n",
       "      <td>0.38125</td>\n",
       "      <td>39.37675</td>\n",
       "      <td>0.190875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name      RMSE      alpha    beta        mu     gamma  \\\n",
       "97  pe_basin_0_0097  1.450777  12.557875  8.1875  2.841925  0.221925   \n",
       "\n",
       "         a_d      b_d       a_w       b_w  \n",
       "97  2.164687  0.38125  39.37675  0.190875  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LHS[df_LHS['RMSE'] == df_LHS.RMSE.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "126ceee2-f4fd-468b-b817-315a0f950828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "pe_basin_5_0000\n",
      "Creating  pe_basin_5_0000\n",
      "pe_basin_5_0001\n",
      "Creating  pe_basin_5_0001\n",
      "pe_basin_5_0002\n",
      "Creating  pe_basin_5_0002\n",
      "pe_basin_5_0003\n",
      "Creating  pe_basin_5_0003\n",
      "pe_basin_5_0004\n",
      "Creating  pe_basin_5_0004\n",
      "pe_basin_5_0005\n",
      "Creating  pe_basin_5_0005\n",
      "pe_basin_5_0006\n",
      "Creating  pe_basin_5_0006\n",
      "pe_basin_5_0007\n",
      "Creating  pe_basin_5_0007\n",
      "pe_basin_5_0008\n",
      "Creating  pe_basin_5_0008\n",
      "pe_basin_5_0009\n",
      "Creating  pe_basin_5_0009\n",
      "pe_basin_5_0010\n",
      "Creating  pe_basin_5_0010\n",
      "pe_basin_5_0011\n",
      "Creating  pe_basin_5_0011\n",
      "pe_basin_5_0012\n",
      "Creating  pe_basin_5_0012\n",
      "pe_basin_5_0013\n",
      "Creating  pe_basin_5_0013\n",
      "pe_basin_5_0014\n",
      "Creating  pe_basin_5_0014\n",
      "pe_basin_5_0015\n",
      "Creating  pe_basin_5_0015\n",
      "pe_basin_5_0016\n",
      "Creating  pe_basin_5_0016\n",
      "pe_basin_5_0017\n",
      "Creating  pe_basin_5_0017\n",
      "pe_basin_5_0018\n",
      "Creating  pe_basin_5_0018\n",
      "pe_basin_5_0019\n",
      "Creating  pe_basin_5_0019\n",
      "Done with iteration:  5\n",
      "6\n",
      "pe_basin_6_0000\n",
      "Creating  pe_basin_6_0000\n",
      "pe_basin_6_0001\n",
      "Creating  pe_basin_6_0001\n",
      "pe_basin_6_0002\n",
      "Creating  pe_basin_6_0002\n",
      "pe_basin_6_0003\n",
      "Creating  pe_basin_6_0003\n",
      "pe_basin_6_0004\n",
      "Creating  pe_basin_6_0004\n",
      "pe_basin_6_0005\n",
      "Creating  pe_basin_6_0005\n",
      "pe_basin_6_0006\n",
      "Creating  pe_basin_6_0006\n",
      "pe_basin_6_0007\n",
      "Creating  pe_basin_6_0007\n",
      "pe_basin_6_0008\n",
      "Creating  pe_basin_6_0008\n",
      "pe_basin_6_0009\n",
      "Creating  pe_basin_6_0009\n",
      "pe_basin_6_0010\n",
      "Creating  pe_basin_6_0010\n",
      "pe_basin_6_0011\n",
      "Creating  pe_basin_6_0011\n",
      "pe_basin_6_0012\n",
      "Creating  pe_basin_6_0012\n",
      "pe_basin_6_0013\n",
      "Creating  pe_basin_6_0013\n",
      "pe_basin_6_0014\n",
      "Creating  pe_basin_6_0014\n",
      "pe_basin_6_0015\n",
      "Creating  pe_basin_6_0015\n",
      "pe_basin_6_0016\n",
      "Creating  pe_basin_6_0016\n",
      "pe_basin_6_0017\n",
      "Creating  pe_basin_6_0017\n",
      "pe_basin_6_0018\n",
      "Creating  pe_basin_6_0018\n",
      "pe_basin_6_0019\n",
      "Creating  pe_basin_6_0019\n",
      "Done with iteration:  6\n",
      "7\n",
      "pe_basin_7_0000\n",
      "Creating  pe_basin_7_0000\n",
      "pe_basin_7_0001\n",
      "Creating  pe_basin_7_0001\n",
      "pe_basin_7_0002\n",
      "Creating  pe_basin_7_0002\n",
      "pe_basin_7_0003\n",
      "Creating  pe_basin_7_0003\n",
      "pe_basin_7_0004\n",
      "Creating  pe_basin_7_0004\n",
      "pe_basin_7_0005\n",
      "Creating  pe_basin_7_0005\n",
      "pe_basin_7_0006\n",
      "Creating  pe_basin_7_0006\n",
      "pe_basin_7_0007\n",
      "Creating  pe_basin_7_0007\n",
      "pe_basin_7_0008\n",
      "Creating  pe_basin_7_0008\n",
      "pe_basin_7_0009\n",
      "Creating  pe_basin_7_0009\n",
      "pe_basin_7_0010\n",
      "Creating  pe_basin_7_0010\n",
      "pe_basin_7_0011\n",
      "Creating  pe_basin_7_0011\n",
      "pe_basin_7_0012\n",
      "Creating  pe_basin_7_0012\n",
      "pe_basin_7_0013\n",
      "Creating  pe_basin_7_0013\n",
      "pe_basin_7_0014\n",
      "Creating  pe_basin_7_0014\n",
      "pe_basin_7_0015\n",
      "Creating  pe_basin_7_0015\n",
      "pe_basin_7_0016\n",
      "Creating  pe_basin_7_0016\n",
      "pe_basin_7_0017\n",
      "Creating  pe_basin_7_0017\n",
      "pe_basin_7_0018\n",
      "Creating  pe_basin_7_0018\n",
      "pe_basin_7_0019\n",
      "Creating  pe_basin_7_0019\n",
      "Done with iteration:  7\n",
      "8\n",
      "pe_basin_8_0000\n",
      "Creating  pe_basin_8_0000\n",
      "pe_basin_8_0001\n",
      "Creating  pe_basin_8_0001\n",
      "pe_basin_8_0002\n",
      "Creating  pe_basin_8_0002\n",
      "pe_basin_8_0003\n",
      "Creating  pe_basin_8_0003\n",
      "pe_basin_8_0004\n",
      "Creating  pe_basin_8_0004\n",
      "pe_basin_8_0005\n",
      "Creating  pe_basin_8_0005\n",
      "pe_basin_8_0006\n",
      "Creating  pe_basin_8_0006\n",
      "pe_basin_8_0007\n",
      "Creating  pe_basin_8_0007\n",
      "pe_basin_8_0008\n",
      "Creating  pe_basin_8_0008\n",
      "pe_basin_8_0009\n",
      "Creating  pe_basin_8_0009\n",
      "pe_basin_8_0010\n",
      "Creating  pe_basin_8_0010\n",
      "pe_basin_8_0011\n",
      "Creating  pe_basin_8_0011\n",
      "pe_basin_8_0012\n",
      "Creating  pe_basin_8_0012\n",
      "pe_basin_8_0013\n",
      "Creating  pe_basin_8_0013\n",
      "pe_basin_8_0014\n",
      "Creating  pe_basin_8_0014\n",
      "pe_basin_8_0015\n",
      "Creating  pe_basin_8_0015\n",
      "pe_basin_8_0016\n",
      "Creating  pe_basin_8_0016\n",
      "pe_basin_8_0017\n",
      "Creating  pe_basin_8_0017\n",
      "pe_basin_8_0018\n",
      "Creating  pe_basin_8_0018\n",
      "pe_basin_8_0019\n",
      "Creating  pe_basin_8_0019\n",
      "Done with iteration:  8\n",
      "9\n",
      "pe_basin_9_0000\n",
      "Creating  pe_basin_9_0000\n",
      "pe_basin_9_0001\n",
      "Creating  pe_basin_9_0001\n",
      "pe_basin_9_0002\n",
      "Creating  pe_basin_9_0002\n",
      "pe_basin_9_0003\n",
      "Creating  pe_basin_9_0003\n",
      "pe_basin_9_0004\n",
      "Creating  pe_basin_9_0004\n",
      "pe_basin_9_0005\n",
      "Creating  pe_basin_9_0005\n",
      "pe_basin_9_0006\n",
      "Creating  pe_basin_9_0006\n",
      "pe_basin_9_0007\n",
      "Creating  pe_basin_9_0007\n",
      "pe_basin_9_0008\n",
      "Creating  pe_basin_9_0008\n",
      "pe_basin_9_0009\n",
      "Creating  pe_basin_9_0009\n",
      "pe_basin_9_0010\n",
      "Creating  pe_basin_9_0010\n",
      "pe_basin_9_0011\n",
      "Creating  pe_basin_9_0011\n",
      "pe_basin_9_0012\n",
      "Creating  pe_basin_9_0012\n",
      "pe_basin_9_0013\n",
      "Creating  pe_basin_9_0013\n",
      "pe_basin_9_0014\n",
      "Creating  pe_basin_9_0014\n",
      "pe_basin_9_0015\n",
      "Creating  pe_basin_9_0015\n",
      "pe_basin_9_0016\n",
      "Creating  pe_basin_9_0016\n",
      "pe_basin_9_0017\n",
      "Creating  pe_basin_9_0017\n",
      "pe_basin_9_0018\n",
      "Creating  pe_basin_9_0018\n",
      "pe_basin_9_0019\n",
      "Creating  pe_basin_9_0019\n",
      "Done with iteration:  9\n"
     ]
    }
   ],
   "source": [
    "param_df = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/Param_range.csv')\n",
    "location = \"pe_basin\"\n",
    "for i in range(5,10):\n",
    "    print(i)\n",
    "    # normalize values\n",
    "    df_LHS = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full_%s.csv'%(i-1))\n",
    "    \n",
    "    scaled = df_LHS.drop([\"Name\", \"temp_rmse\"], axis = 1)/normalization_scalar\n",
    "\n",
    "    # start training the surrogate models\n",
    "    nInput, nOutput = len(param_df), 1\n",
    "    alpha = 1e-4\n",
    "    lb = 1e-4\n",
    "    ub = 1e3\n",
    "\n",
    "    # perform optimization using the surrogate model\n",
    "    gen = 100\n",
    "    crossover_rate = 0.9\n",
    "    mu = 20\n",
    "    mum = 20\n",
    "    N_resample = 20\n",
    "    leng_lb = 1e-4\n",
    "    leng_ub = 1e3\n",
    "    nu = 1.5\n",
    "    pop = 100\n",
    "\n",
    "    # start training the surrogate models\n",
    "    x = scaled.values\n",
    "    y = df_LHS[\"temp_rmse\"].values\n",
    "\n",
    "    xlb_single_value_scaled = param_df['Min_Value']/normalization_scalar\n",
    "    xub_single_value_scaled = param_df['Max_Value']/normalization_scalar\n",
    "\n",
    "    sm = gp.GPR_Matern(x, y, nInput, nOutput, x.shape[0], xlb_single_value_scaled, xub_single_value_scaled, alpha=alpha, leng_sb=[leng_lb,leng_ub], nu=nu)\n",
    "\n",
    "    bestx_sm, besty_sm, x_sm, y_sm = \\\n",
    "        NSGA2.optimization(sm, nInput, nOutput, xlb_single_value_scaled.values, xub_single_value_scaled.values, \\\n",
    "                           pop, gen, crossover_rate, mu, mum)\n",
    "    D = NSGA2.crowding_distance(besty_sm)\n",
    "    idxr = D.argsort()[::-1][:N_resample]\n",
    "    x_resample = bestx_sm[idxr,:]\n",
    "    y_resample = np.zeros((N_resample,nOutput))\n",
    "\n",
    "    # create test id\n",
    "    test_id_list=[]\n",
    "    for id_ in range(N_resample):\n",
    "        test_id = '%s_%s_%s'%(location, \"%i\"%i, \"%04i\"%(id_))\n",
    "        test_id_list.append(test_id)\n",
    "    psets_df_new = pd.DataFrame(x_resample, columns=param_df['Var_name'].values, index=test_id_list)\n",
    "\n",
    "    psets_df_new = psets_df_new*normalization_scalar\n",
    "\n",
    "    psets_df_new.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/Opt_runs_%s.csv'%i)\n",
    "    \n",
    "    psets_df_new.index=psets_df_new.index.set_names(['Name'])\n",
    "    psets_df_new = psets_df_new.reset_index()\n",
    "    \n",
    "    RMSE =[]\n",
    "    comid_list =[]\n",
    "    name_list=[]\n",
    "    outlet_list =[]\n",
    "    with warnings.catch_warnings(record=True):\n",
    "\n",
    "        for folder in np.unique(psets_df_new.Name.values):\n",
    "            print(folder)\n",
    "            var_list = psets_df_new[psets_df_new['Name'] == folder]\n",
    "\n",
    "            alpha = var_list.alpha.values[0]\n",
    "            beta = var_list.beta.values[0]\n",
    "            mu = var_list.mu.values[0]\n",
    "            gamma = var_list.gamma.values[0]\n",
    "\n",
    "            # Build Output Folders\n",
    "            path = '/glade/scratch/dblaskey/RBM/Regression/Opt/%s/'%folder\n",
    "            if os.path.exists(path) == False:           \n",
    "                print(\"Creating \", folder)\n",
    "                os.mkdir(path)\n",
    "\n",
    "            for outlet in outlets:\n",
    "                Ordered_reaches_final = pd.read_csv(\"/glade/scratch/dblaskey/RBM/Input/%s_network.csv\"%outlet)\n",
    "                comid = df_sites[df_sites['outlet_comid'] == outlet]['COMID'].values[0]\n",
    "                cell = Ordered_reaches_final[Ordered_reaches_final['hru'] == comid].node.values[0]\n",
    "                site_no = df_sites[df_sites['outlet_comid'] == outlet].index.values[0]\n",
    "\n",
    "                Water = []\n",
    "                for year in years:\n",
    "                    test = pd.read_csv(\"/glade/scratch/dblaskey/RBM/RBM_Input/%s_energy_%s\"%(outlet,year), sep=\" \", header = None,\n",
    "                    names=[\"cell\", \"Tair\", \"vp\", \"SW\", \"LW\", \"Density\",\"P\",\"Wind\"])\n",
    "                    test_id = test[test[\"cell\"] == cell]\n",
    "                    test_id.drop(test_id.tail(1).index,inplace=True)\n",
    "                    test_id['T_smooth'] = gaussian_filter1d(test_id['Tair'], sigma=5)\n",
    "\n",
    "                    Water.append(test_id.apply(lambda row : mosheni(row['T_smooth']), axis = 1))\n",
    "\n",
    "                Water=np.concatenate(Water)                        \n",
    "                sim_df = pd.DataFrame(Water, index=time_series, columns=['sim'])\n",
    "                sim_df.index.name = 'Date'\n",
    "                sim_df.to_csv('/glade/scratch/dblaskey/RBM/Regression/Opt/%s/%s.csv'%(folder,outlet))\n",
    "\n",
    "                # Filter to just one gage for observations\n",
    "                temp_df = df[df['site_no']==site_no][['X_00010_00003', 'Date']]\n",
    "                temp_df = temp_df.rename(columns={\"X_00010_00003\": \"obs\"})\n",
    "                temp_df = temp_df.set_index('Date')\n",
    "                temp_df.index = pd.to_datetime(temp_df.index)\n",
    "\n",
    "                # Combine simulation and observation datasets\n",
    "                df_concat = pd.concat([sim_df,temp_df],axis=1)\n",
    "                df_concat = df_concat.dropna()\n",
    "                df_concat = df_concat.loc['2013-10-01':'2017-09-30']\n",
    "                df_concat = df_concat[df_concat.index.month.isin([5,6,7,8,9])]\n",
    "                df_concat = df_concat.reset_index()\n",
    "\n",
    "                RMSE.append(he.evaluator(he.rmse, df_concat.sim.values, df_concat.obs.values)[0])\n",
    "                comid_list.append(np.int(comid))\n",
    "                name_list.append(folder)\n",
    "                outlet_list.append(outlet)\n",
    "                        \n",
    "        df_temp = pd.DataFrame({'temp_rmse': RMSE,  'COMID': comid_list, 'Name': name_list, 'Outlet': outlet_list})\n",
    "        df2 = pd.merge(df_temp, df_sites, on=['COMID'])\n",
    "        df2.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_%s.csv'%i, index=False)\n",
    "\n",
    "        df_LHS_new = df_temp.groupby('Name').mean(\"temp_rmse\").reset_index().drop(columns=['COMID', 'Outlet'])\n",
    "        df_LHS_new = df_LHS_new.merge(psets_df_new)\n",
    "        \n",
    "        df_LHS_new = pd.concat([df_LHS, df_LHS_new]).reset_index(drop=True)\n",
    "\n",
    "        df_LHS_new.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full_%s.csv'%i, index=False)\n",
    "        warnings.warn(\"should not appear\")\n",
    "\n",
    "    print(\"Done with iteration: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f18e2f83-3740-4375-a677-0666c349a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for local in np.unique(df_sites.Location.values):\n",
    "    df_temp_loc = df_temp[df_temp['Location']==local]\n",
    "    \n",
    "    df_temp_loc = df_temp_loc[['Name', 'temp_rmse']]\n",
    "\n",
    "    df_LHS_loc = df_temp_loc.groupby('Name').mean(\"temp_rmse\").reset_index()\n",
    "    df_LHS_loc = df_LHS_loc.merge(psets_df)\n",
    "\n",
    "    df_LHS_loc = df_LHS_loc.drop([\"min_velocity\", \"min_d\", \"min_w\"], axis = 1)\n",
    "\n",
    "    df_LHS_loc.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full_0-%s.csv'%local, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25367e00-ea04-40e9-bf39-b56d125606d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "pe_basin_1_0000\n",
      "pe_basin_1_0001\n",
      "pe_basin_1_0002\n",
      "pe_basin_1_0003\n",
      "pe_basin_1_0004\n",
      "pe_basin_1_0005\n",
      "pe_basin_1_0006\n",
      "pe_basin_1_0007\n",
      "pe_basin_1_0008\n",
      "pe_basin_1_0009\n",
      "pe_basin_1_0010\n",
      "pe_basin_1_0011\n",
      "pe_basin_1_0012\n",
      "pe_basin_1_0013\n",
      "pe_basin_1_0014\n",
      "pe_basin_1_0015\n",
      "pe_basin_1_0016\n",
      "pe_basin_1_0017\n",
      "pe_basin_1_0018\n",
      "pe_basin_1_0019\n",
      "Done with iteration:  1\n",
      "pe_basin_1_0000\n",
      "pe_basin_1_0001\n",
      "pe_basin_1_0002\n",
      "pe_basin_1_0003\n",
      "pe_basin_1_0004\n",
      "pe_basin_1_0005\n",
      "pe_basin_1_0006\n",
      "pe_basin_1_0007\n",
      "pe_basin_1_0008\n",
      "pe_basin_1_0009\n",
      "pe_basin_1_0010\n",
      "pe_basin_1_0011\n",
      "pe_basin_1_0012\n",
      "pe_basin_1_0013\n",
      "pe_basin_1_0014\n",
      "pe_basin_1_0015\n",
      "pe_basin_1_0016\n",
      "pe_basin_1_0017\n",
      "pe_basin_1_0018\n",
      "pe_basin_1_0019\n",
      "Done with iteration:  1\n",
      "pe_basin_1_0000\n",
      "pe_basin_1_0001\n",
      "pe_basin_1_0002\n",
      "pe_basin_1_0003\n",
      "pe_basin_1_0004\n",
      "pe_basin_1_0005\n",
      "pe_basin_1_0006\n",
      "pe_basin_1_0007\n",
      "pe_basin_1_0008\n",
      "pe_basin_1_0009\n",
      "pe_basin_1_0010\n",
      "pe_basin_1_0011\n",
      "pe_basin_1_0012\n",
      "pe_basin_1_0013\n",
      "pe_basin_1_0014\n",
      "pe_basin_1_0015\n",
      "pe_basin_1_0016\n",
      "pe_basin_1_0017\n",
      "pe_basin_1_0018\n",
      "pe_basin_1_0019\n",
      "Done with iteration:  1\n",
      "2\n",
      "pe_basin_2_0000\n",
      "pe_basin_2_0001\n",
      "pe_basin_2_0002\n",
      "pe_basin_2_0003\n",
      "pe_basin_2_0004\n",
      "pe_basin_2_0005\n",
      "pe_basin_2_0006\n",
      "pe_basin_2_0007\n",
      "pe_basin_2_0008\n",
      "pe_basin_2_0009\n",
      "pe_basin_2_0010\n",
      "pe_basin_2_0011\n",
      "pe_basin_2_0012\n",
      "pe_basin_2_0013\n",
      "pe_basin_2_0014\n",
      "pe_basin_2_0015\n",
      "pe_basin_2_0016\n",
      "pe_basin_2_0017\n",
      "pe_basin_2_0018\n",
      "pe_basin_2_0019\n",
      "Done with iteration:  2\n",
      "pe_basin_2_0000\n",
      "pe_basin_2_0001\n",
      "pe_basin_2_0002\n",
      "pe_basin_2_0003\n",
      "pe_basin_2_0004\n",
      "pe_basin_2_0005\n",
      "pe_basin_2_0006\n",
      "pe_basin_2_0007\n",
      "pe_basin_2_0008\n",
      "pe_basin_2_0009\n",
      "pe_basin_2_0010\n",
      "pe_basin_2_0011\n",
      "pe_basin_2_0012\n",
      "pe_basin_2_0013\n",
      "pe_basin_2_0014\n",
      "pe_basin_2_0015\n",
      "pe_basin_2_0016\n",
      "pe_basin_2_0017\n",
      "pe_basin_2_0018\n",
      "pe_basin_2_0019\n",
      "Done with iteration:  2\n",
      "pe_basin_2_0000\n",
      "pe_basin_2_0001\n",
      "pe_basin_2_0002\n",
      "pe_basin_2_0003\n",
      "pe_basin_2_0004\n",
      "pe_basin_2_0005\n",
      "pe_basin_2_0006\n",
      "pe_basin_2_0007\n",
      "pe_basin_2_0008\n",
      "pe_basin_2_0009\n",
      "pe_basin_2_0010\n",
      "pe_basin_2_0011\n",
      "pe_basin_2_0012\n",
      "pe_basin_2_0013\n",
      "pe_basin_2_0014\n",
      "pe_basin_2_0015\n",
      "pe_basin_2_0016\n",
      "pe_basin_2_0017\n",
      "pe_basin_2_0018\n",
      "pe_basin_2_0019\n",
      "Done with iteration:  2\n",
      "3\n",
      "pe_basin_3_0000\n",
      "pe_basin_3_0001\n",
      "pe_basin_3_0002\n",
      "pe_basin_3_0003\n",
      "pe_basin_3_0004\n",
      "pe_basin_3_0005\n",
      "pe_basin_3_0006\n",
      "pe_basin_3_0007\n",
      "pe_basin_3_0008\n",
      "pe_basin_3_0009\n",
      "pe_basin_3_0010\n",
      "pe_basin_3_0011\n",
      "pe_basin_3_0012\n",
      "pe_basin_3_0013\n",
      "pe_basin_3_0014\n",
      "pe_basin_3_0015\n",
      "pe_basin_3_0016\n",
      "pe_basin_3_0017\n",
      "pe_basin_3_0018\n",
      "pe_basin_3_0019\n",
      "Done with iteration:  3\n",
      "pe_basin_3_0000\n",
      "pe_basin_3_0001\n",
      "pe_basin_3_0002\n",
      "pe_basin_3_0003\n",
      "pe_basin_3_0004\n",
      "pe_basin_3_0005\n",
      "pe_basin_3_0006\n",
      "pe_basin_3_0007\n",
      "pe_basin_3_0008\n",
      "pe_basin_3_0009\n",
      "pe_basin_3_0010\n",
      "pe_basin_3_0011\n",
      "pe_basin_3_0012\n",
      "pe_basin_3_0013\n",
      "pe_basin_3_0014\n",
      "pe_basin_3_0015\n",
      "pe_basin_3_0016\n",
      "pe_basin_3_0017\n",
      "pe_basin_3_0018\n",
      "pe_basin_3_0019\n",
      "Done with iteration:  3\n",
      "pe_basin_3_0000\n",
      "pe_basin_3_0001\n",
      "pe_basin_3_0002\n",
      "pe_basin_3_0003\n",
      "pe_basin_3_0004\n",
      "pe_basin_3_0005\n",
      "pe_basin_3_0006\n",
      "pe_basin_3_0007\n",
      "pe_basin_3_0008\n",
      "pe_basin_3_0009\n",
      "pe_basin_3_0010\n",
      "pe_basin_3_0011\n",
      "pe_basin_3_0012\n",
      "pe_basin_3_0013\n",
      "pe_basin_3_0014\n",
      "pe_basin_3_0015\n",
      "pe_basin_3_0016\n",
      "pe_basin_3_0017\n",
      "pe_basin_3_0018\n",
      "pe_basin_3_0019\n",
      "Done with iteration:  3\n",
      "4\n",
      "pe_basin_4_0000\n",
      "pe_basin_4_0001\n",
      "pe_basin_4_0002\n",
      "pe_basin_4_0003\n",
      "pe_basin_4_0004\n",
      "pe_basin_4_0005\n",
      "pe_basin_4_0006\n",
      "pe_basin_4_0007\n",
      "pe_basin_4_0008\n",
      "pe_basin_4_0009\n",
      "pe_basin_4_0010\n",
      "pe_basin_4_0011\n",
      "pe_basin_4_0012\n",
      "pe_basin_4_0013\n",
      "pe_basin_4_0014\n",
      "pe_basin_4_0015\n",
      "pe_basin_4_0016\n",
      "pe_basin_4_0017\n",
      "pe_basin_4_0018\n",
      "pe_basin_4_0019\n",
      "Done with iteration:  4\n",
      "pe_basin_4_0000\n",
      "pe_basin_4_0001\n",
      "pe_basin_4_0002\n",
      "pe_basin_4_0003\n",
      "pe_basin_4_0004\n",
      "pe_basin_4_0005\n",
      "pe_basin_4_0006\n",
      "pe_basin_4_0007\n",
      "pe_basin_4_0008\n",
      "pe_basin_4_0009\n",
      "pe_basin_4_0010\n",
      "pe_basin_4_0011\n",
      "pe_basin_4_0012\n",
      "pe_basin_4_0013\n",
      "pe_basin_4_0014\n",
      "pe_basin_4_0015\n",
      "pe_basin_4_0016\n",
      "pe_basin_4_0017\n",
      "pe_basin_4_0018\n",
      "pe_basin_4_0019\n",
      "Done with iteration:  4\n",
      "pe_basin_4_0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6f1181e2ba11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0mtest_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T_smooth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_filter1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tair'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         \u001b[0mWater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmosheni\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T_smooth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mWater\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7539\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7540\u001b[0m         )\n\u001b[0;32m-> 7541\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mseries_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### By Location ###\n",
    "param_df = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/Param_range.csv')\n",
    "location = \"pe_basin\"\n",
    "\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    for local in np.unique(df_sites.Location.values):\n",
    "        # normalize values\n",
    "        df_LHS = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full_%s-%s.csv'%(i-1, local))\n",
    "\n",
    "        scaled = df_LHS.drop([\"Name\", \"temp_rmse\"], axis = 1)/normalization_scalar\n",
    "\n",
    "        # start training the surrogate models\n",
    "        nInput, nOutput = len(param_df), 1\n",
    "        alpha = 1e-4\n",
    "        lb = 1e-4\n",
    "        ub = 1e3\n",
    "\n",
    "        # perform optimization using the surrogate model\n",
    "        gen = 100\n",
    "        crossover_rate = 0.9\n",
    "        mu = 20\n",
    "        mum = 20\n",
    "        N_resample = 20\n",
    "        leng_lb = 1e-4\n",
    "        leng_ub = 1e3\n",
    "        nu = 1.5\n",
    "        pop = 100\n",
    "\n",
    "        # start training the surrogate models\n",
    "        x = scaled.values\n",
    "        y = df_LHS[\"temp_rmse\"].values\n",
    "\n",
    "        xlb_single_value_scaled = param_df['Min_Value']/normalization_scalar\n",
    "        xub_single_value_scaled = param_df['Max_Value']/normalization_scalar\n",
    "\n",
    "        sm = gp.GPR_Matern(x, y, nInput, nOutput, x.shape[0], xlb_single_value_scaled, xub_single_value_scaled, alpha=alpha, leng_sb=[leng_lb,leng_ub], nu=nu)\n",
    "\n",
    "        bestx_sm, besty_sm, x_sm, y_sm = \\\n",
    "            NSGA2.optimization(sm, nInput, nOutput, xlb_single_value_scaled.values, xub_single_value_scaled.values, \\\n",
    "                               pop, gen, crossover_rate, mu, mum)\n",
    "        D = NSGA2.crowding_distance(besty_sm)\n",
    "        idxr = D.argsort()[::-1][:N_resample]\n",
    "        x_resample = bestx_sm[idxr,:]\n",
    "        y_resample = np.zeros((N_resample,nOutput))\n",
    "\n",
    "        # create test id\n",
    "        test_id_list=[]\n",
    "        for id_ in range(N_resample):\n",
    "            test_id = '%s_%s_%s'%(location, \"%i\"%i, \"%04i\"%(id_))\n",
    "            test_id_list.append(test_id)\n",
    "        psets_df_new = pd.DataFrame(x_resample, columns=param_df['Var_name'].values, index=test_id_list)\n",
    "\n",
    "        psets_df_new = psets_df_new*normalization_scalar\n",
    "\n",
    "        psets_df_new.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/Opt_runs_%s_%s.csv'%(local,i))\n",
    "\n",
    "        psets_df_new.index=psets_df_new.index.set_names(['Name'])\n",
    "        psets_df_new = psets_df_new.reset_index()\n",
    "\n",
    "        RMSE =[]\n",
    "        comid_list =[]\n",
    "        name_list=[]\n",
    "        outlet_list =[]\n",
    "        with warnings.catch_warnings(record=True):\n",
    "\n",
    "            for folder in np.unique(psets_df_new.Name.values):\n",
    "                print(folder)\n",
    "                var_list = psets_df_new[psets_df_new['Name'] == folder]\n",
    "\n",
    "                alpha = var_list.alpha.values[0]\n",
    "                beta = var_list.beta.values[0]\n",
    "                mu = var_list.mu.values[0]\n",
    "                gamma = var_list.gamma.values[0]\n",
    "\n",
    "                # Build Output Folders\n",
    "                path = '/glade/scratch/dblaskey/RBM/Regression/Opt/%s/'%folder\n",
    "                if os.path.exists(path) == False:           \n",
    "                    print(\"Creating \", folder)\n",
    "                    os.mkdir(path)\n",
    "\n",
    "                for outlet in outlets:\n",
    "                    Ordered_reaches_final = pd.read_csv(\"/glade/scratch/dblaskey/RBM/Input/%s_network.csv\"%outlet)\n",
    "                    comid = df_sites[df_sites['outlet_comid'] == outlet]['COMID'].values[0]\n",
    "                    cell = Ordered_reaches_final[Ordered_reaches_final['hru'] == comid].node.values[0]\n",
    "                    site_no = df_sites[df_sites['outlet_comid'] == outlet].index.values[0]\n",
    "\n",
    "                    Water = []\n",
    "                    for year in years:\n",
    "                        test = pd.read_csv(\"/glade/scratch/dblaskey/RBM/RBM_Input/%s_energy_%s\"%(outlet,year), sep=\" \", header = None,\n",
    "                        names=[\"cell\", \"Tair\", \"vp\", \"SW\", \"LW\", \"Density\",\"P\",\"Wind\"])\n",
    "                        test_id = test[test[\"cell\"] == cell]\n",
    "                        test_id.drop(test_id.tail(1).index,inplace=True)\n",
    "                        test_id['T_smooth'] = gaussian_filter1d(test_id['Tair'], sigma=5)\n",
    "\n",
    "                        Water.append(test_id.apply(lambda row : mosheni(row['T_smooth']), axis = 1))\n",
    "\n",
    "                    Water=np.concatenate(Water)                        \n",
    "                    sim_df = pd.DataFrame(Water, index=time_series, columns=['sim'])\n",
    "                    sim_df.index.name = 'Date'\n",
    "                    sim_df.to_csv('/glade/scratch/dblaskey/RBM/Regression/Opt/%s/%s.csv'%(folder,outlet))\n",
    "\n",
    "                    # Filter to just one gage for observations\n",
    "                    temp_df = df[df['site_no']==site_no][['X_00010_00003', 'Date']]\n",
    "                    temp_df = temp_df.rename(columns={\"X_00010_00003\": \"obs\"})\n",
    "                    temp_df = temp_df.set_index('Date')\n",
    "                    temp_df.index = pd.to_datetime(temp_df.index)\n",
    "\n",
    "                    # Combine simulation and observation datasets\n",
    "                    df_concat = pd.concat([sim_df,temp_df],axis=1)\n",
    "                    df_concat = df_concat.dropna()\n",
    "                    df_concat = df_concat.loc['2013-10-01':'2017-09-30']\n",
    "                    df_concat = df_concat[df_concat.index.month.isin([5,6,7,8,9])]\n",
    "                    df_concat = df_concat.reset_index()\n",
    "\n",
    "                    RMSE.append(he.evaluator(he.rmse, df_concat.sim.values, df_concat.obs.values)[0])\n",
    "                    comid_list.append(np.int(comid))\n",
    "                    name_list.append(folder)\n",
    "                    outlet_list.append(outlet)\n",
    "\n",
    "            df_temp = pd.DataFrame({'temp_rmse': RMSE,  'COMID': comid_list, 'Name': name_list, 'Outlet': outlet_list})\n",
    "            df2 = pd.merge(df_temp, df_sites, on=['COMID'])\n",
    "            df2.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_%s-%s.csv'%(i, local), index=False)\n",
    "\n",
    "            df_LHS_new = df_temp.groupby('Name').mean(\"temp_rmse\").reset_index().drop(columns=['COMID', 'Outlet'])\n",
    "            df_LHS_new = df_LHS_new.merge(psets_df_new)\n",
    "\n",
    "            df_LHS_new = pd.concat([df_LHS, df_LHS_new]).reset_index(drop=True)\n",
    "\n",
    "            df_LHS_new.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full_%s-%s.csv'%(i, local), index=False)\n",
    "            warnings.warn(\"should not appear\")\n",
    "\n",
    "        print(\"Done with iteration: \", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130133b8-7135-4959-b568-4f7fd634b7bf",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9724132-4870-4a77-8253-12015912937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('/glade/u/home/dblaskey/RBM/Regression_Model/LHS_results_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "788aea98-6a54-4bab-8836-73f1f45c995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "psets_df = df_results[df_results['RMSE'] == df_results.RMSE.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019e9563-384f-46d5-816d-148f4ebe2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Begin Code #####\n",
    "df_sites = pd.read_csv('/glade/u/home/dblaskey/RBM/Validation/Val_Basins.csv', index_col=0)\n",
    "outlets = np.unique(df_sites.outlet_comid.values)\n",
    "\n",
    "# Read in Observed Data\n",
    "temp_data = pd.read_csv('/glade/scratch/dblaskey/RBM/temperature_gages.csv', index_col=0)\n",
    "df = pd.merge(temp_data, df_sites, on=\"site_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70ebfc6-3327-4333-93b2-9c37540ede20",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2017,2022)\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2021-09-30'\n",
    "time_series = pd.date_range(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b341825-011f-462e-a2e0-d129e7671ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE =[]\n",
    "comid_list =[]\n",
    "outlet_list =[]\n",
    "with warnings.catch_warnings(record=True):\n",
    "    \n",
    "    alpha = psets_df.alpha.values[0]\n",
    "    beta = psets_df.beta.values[0]\n",
    "    mu = psets_df.mu.values[0]\n",
    "    gamma = psets_df.gamma.values[0]\n",
    "\n",
    "    for outlet in outlets:\n",
    "        Ordered_reaches_final = pd.read_csv(\"/glade/scratch/dblaskey/RBM/Input/%s_network.csv\"%outlet)\n",
    "        comids = df_sites[df_sites['outlet_comid'] == outlet]['COMID'].values\n",
    "        site_nos = df_sites[df_sites['outlet_comid'] == outlet].index.values\n",
    "        \n",
    "        for i,comid in enumerate(comids):\n",
    "            print(comid)\n",
    "            site_no = site_nos[i]\n",
    "            cell = Ordered_reaches_final[Ordered_reaches_final['hru'] == comid].node.values[0]\n",
    "            \n",
    "            Water = []\n",
    "            for year in years:\n",
    "                test = pd.read_csv(\"/glade/scratch/dblaskey/RBM/RBM_Input/%s_energy_%s\"%(outlet,year), sep=\" \", header = None,\n",
    "                names=[\"cell\", \"Tair\", \"vp\", \"SW\", \"LW\", \"Density\",\"P\",\"Wind\"])\n",
    "                test_id = test[test[\"cell\"] == cell]\n",
    "                test_id.drop(test_id.tail(1).index,inplace=True)\n",
    "                test_id['T_smooth'] = 0.1 * test_id['Tair'] + 0.9 * test_id['Tair'].shift()\n",
    "                test_id['T_smooth']=test_id['T_smooth'].fillna(test_id['Tair'])\n",
    "\n",
    "                Water.append(test_id.apply(lambda row : mosheni(row['T_smooth']), axis = 1))\n",
    "\n",
    "            Water=np.concatenate(Water)                        \n",
    "            sim_df = pd.DataFrame(Water, index=time_series, columns=['sim'])\n",
    "            sim_df.index.name = 'Date'\n",
    "            sim_df.to_csv('/glade/scratch/dblaskey/RBM/Regression/Val/%s.csv'%(comid))\n",
    "\n",
    "            # Filter to just one gage for observations\n",
    "            temp_df = df[df['site_no']==site_no][['X_00010_00003', 'Date']]\n",
    "            temp_df = temp_df.rename(columns={\"X_00010_00003\": \"obs\"})\n",
    "            temp_df = temp_df.set_index('Date')\n",
    "            temp_df.index = pd.to_datetime(temp_df.index)\n",
    "\n",
    "            # Combine simulation and observation datasets\n",
    "            df_concat = pd.concat([sim_df,temp_df],axis=1)\n",
    "            df_concat = df_concat.dropna()\n",
    "            df_concat = df_concat.loc['2017-10-01':'2021-09-30']\n",
    "            df_concat = df_concat[df_concat.index.month.isin([5,6,7,8,9])]\n",
    "            df_concat = df_concat.reset_index()\n",
    "\n",
    "            RMSE.append(he.evaluator(he.rmse, df_concat.sim.values, df_concat.obs.values)[0])\n",
    "            comid_list.append(np.int(comid))\n",
    "            outlet_list.append(outlet)\n",
    "    warnings.warn(\"should not appear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8d6a93e-cb0b-4577-98f7-df4db526c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the results\n",
    "df_temp = pd.DataFrame({'temp_rmse': RMSE,  'COMID': comid_list, 'Outlet': outlet_list})\n",
    "df2 = pd.merge(df_temp, df_sites, on=['COMID'])\n",
    "df2.to_csv('/glade/u/home/dblaskey/RBM/Regression_Model/val_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7155c16b-7693-4a1e-ba16-7c091c02ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8698513461813593"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.temp_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31a60624-7b0e-4ec4-aa72-61d989c4955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Interior    2.897326\n",
       "North       4.092079\n",
       "South       2.314640\n",
       "Name: temp_rmse, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('Location').temp_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8eb461db-bdde-4ec2-898a-1a8369f00fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "OB    3.104329\n",
       "OG    2.497781\n",
       "VB    3.137267\n",
       "VG    2.889884\n",
       "Name: temp_rmse, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('type').temp_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd951c-4a85-4924-840d-de1042c70680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
